{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fccab3e0",
   "metadata": {},
   "source": [
    "# Advanced Data Cleaning and Imputation\n",
    "This notebook demonstrates advanced methods for handling missing values and outliers in the housing dataset, including structural filling, ordinal encoding, iterative imputation, and predictive imputation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1732ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55952f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data\n",
    "train_df = pd.read_csv('../../data/raw/train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dcb5ed",
   "metadata": {},
   "source": [
    "## Inspect Missing Values\n",
    "Check for missing values in the dataset to identify columns that need advanced imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a30a562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolQC          1453\n",
       "MiscFeature     1406\n",
       "Alley           1369\n",
       "Fence           1179\n",
       "MasVnrType       872\n",
       "FireplaceQu      690\n",
       "LotFrontage      259\n",
       "GarageType        81\n",
       "GarageYrBlt       81\n",
       "GarageFinish      81\n",
       "GarageQual        81\n",
       "GarageCond        81\n",
       "BsmtFinType2      38\n",
       "BsmtExposure      38\n",
       "BsmtFinType1      37\n",
       "BsmtCond          37\n",
       "BsmtQual          37\n",
       "MasVnrArea         8\n",
       "Electrical         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display missing value counts\n",
    "missing = train_df.isnull().sum()\n",
    "missing[missing > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317bdb24",
   "metadata": {},
   "source": [
    "## Handling Structural Missing Values\n",
    "Some features have missing values that indicate the absence of a feature (e.g., no garage, no alley access). These should be filled with a specific value like 'None' before advanced imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83e6714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill structural missing values with 'None' for relevant categorical features\n",
    "structural_none_features = ['Alley', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "                            'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "                            'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "for col in structural_none_features:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e4e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive imputation for a categorical column (e.g., GarageType)\n",
    "feature = 'GarageType'\n",
    "if train_df[feature].isnull().sum() > 0:\n",
    "    not_null = train_df[train_df[feature].notnull()]\n",
    "    null = train_df[train_df[feature].isnull()]\n",
    "    predictors = [col for col in train_df.columns if col not in [feature, 'SalePrice']]\n",
    "    X = pd.get_dummies(not_null[predictors], dummy_na=True)\n",
    "    X_null = pd.get_dummies(null[predictors], dummy_na=True)\n",
    "    X_null = X_null.reindex(columns=X.columns, fill_value=0)\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    clf.fit(X, not_null[feature])\n",
    "    train_df.loc[train_df[feature].isnull(), feature] = clf.predict(X_null)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af28e379",
   "metadata": {},
   "source": [
    "## Define Ordinal Features and Quality Mapping\n",
    "Some features have a natural order (e.g., quality ratings). We'll define these before feature grouping to handle them appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0469cedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal features found: ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\n"
     ]
    }
   ],
   "source": [
    "# Define quality-related features and their order\n",
    "quality_map = ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "ordinal_features = [\n",
    "    'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC',\n",
    "    'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC'\n",
    "]\n",
    "# Ensure all ordinal features are present in the data\n",
    "ordinal_features = [col for col in ordinal_features if col in train_df.columns]\n",
    "print(f\"Ordinal features found: {ordinal_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5685378d",
   "metadata": {},
   "source": [
    "## Feature Grouping for Preprocessing\n",
    "Split features into numeric, ordinal, and categorical groups for separate preprocessing pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fcb9b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: 37\n",
      "Ordinal features: 10\n",
      "Categorical features: 33\n"
     ]
    }
   ],
   "source": [
    "# Identify numeric and categorical columns (excluding target and ordinal features)\n",
    "numeric_features = train_df.select_dtypes(include=[np.number]).columns.drop('SalePrice', errors='ignore')\n",
    "categorical_features = [col for col in train_df.select_dtypes(include='object').columns \n",
    "                       if col not in ordinal_features]\n",
    "print(f\"Numeric features: {len(numeric_features)}\")\n",
    "print(f\"Ordinal features: {len(ordinal_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc61b8b",
   "metadata": {},
   "source": [
    "## Build Comprehensive Preprocessing Pipeline\n",
    "Use scikit-learn's ColumnTransformer to apply different preprocessing strategies:\n",
    "- **Numeric**: Iterative imputation + scaling\n",
    "- **Ordinal**: Constant imputation + ordinal encoding\n",
    "- **Categorical**: Constant imputation + one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b202623d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data shape: (1460, 264)\n"
     ]
    }
   ],
   "source": [
    "# Define preprocessing pipelines for each feature type\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', IterativeImputer(\n",
    "        estimator=RandomForestRegressor(n_estimators=50),\n",
    "        max_iter=10, random_state=0)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "ordinal_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='None')),\n",
    "    ('ordinal', OrdinalEncoder(categories=[quality_map]*len(ordinal_features), handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='None')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "# Combine all pipelines using ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, numeric_features),\n",
    "    ('ord', ordinal_pipeline, ordinal_features),\n",
    "    ('cat', categorical_pipeline, categorical_features)\n",
    "])\n",
    "# Fit and transform the data (excluding target)\n",
    "X_clean = preprocessor.fit_transform(train_df.drop(columns='SalePrice'))\n",
    "print(f\"Preprocessed data shape: {X_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566896ad",
   "metadata": {},
   "source": [
    "## Advanced Predictive Imputation for Categorical Features\n",
    "Use predictive modeling to fill missing categorical values (example for GarageType)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4098833",
   "metadata": {},
   "source": [
    "# Convert Preprocessed Data to DataFrame with Numeric Features\n",
    "After preprocessing, the output is a NumPy array. To make it easier to work with, convert it back to a DataFrame with proper column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abf4ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Id  MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  \\\n",
      "0 -1.730865    0.073375    -0.252202 -0.207142     0.651479    -0.517200   \n",
      "1 -1.728492   -0.872563     0.391456 -0.091886    -0.071836     2.179628   \n",
      "2 -1.726120    0.073375    -0.123471  0.073480     0.651479    -0.517200   \n",
      "3 -1.723747    0.309859    -0.466755 -0.096897     0.651479    -0.517200   \n",
      "4 -1.721374    0.073375     0.563098  0.375148     1.374795    -0.517200   \n",
      "\n",
      "   YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  SaleType_ConLw  \\\n",
      "0   1.050994      0.878668    0.509962    0.575425  ...             0.0   \n",
      "1   0.156734     -0.429577   -0.575140    1.171992  ...             0.0   \n",
      "2   0.984752      0.830215    0.321730    0.092907  ...             0.0   \n",
      "3  -1.863632     -0.720298   -0.575140   -0.499274  ...             0.0   \n",
      "4   0.951632      0.733308    1.362543    0.463568  ...             0.0   \n",
      "\n",
      "   SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  \\\n",
      "0           0.0           0.0          1.0                    0.0   \n",
      "1           0.0           0.0          1.0                    0.0   \n",
      "2           0.0           0.0          1.0                    0.0   \n",
      "3           0.0           0.0          1.0                    1.0   \n",
      "4           0.0           0.0          1.0                    0.0   \n",
      "\n",
      "   SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
      "0                    0.0                   0.0                   0.0   \n",
      "1                    0.0                   0.0                   0.0   \n",
      "2                    0.0                   0.0                   0.0   \n",
      "3                    0.0                   0.0                   0.0   \n",
      "4                    0.0                   0.0                   0.0   \n",
      "\n",
      "   SaleCondition_Normal  SaleCondition_Partial  \n",
      "0                   1.0                    0.0  \n",
      "1                   1.0                    0.0  \n",
      "2                   1.0                    0.0  \n",
      "3                   0.0                    0.0  \n",
      "4                   1.0                    0.0  \n",
      "\n",
      "[5 rows x 264 columns]\n",
      "All features are now numeric. Shape: (1460, 264)\n"
     ]
    }
   ],
   "source": [
    "# Convert preprocessed data to DataFrame with feature names\n",
    "# Get feature names for each transformer\n",
    "num_cols = list(numeric_features)\n",
    "ord_cols = list(ordinal_features)\n",
    "cat_cols = list(preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features))\n",
    "all_cols = num_cols + ord_cols + list(cat_cols)\n",
    "\n",
    "import scipy.sparse\n",
    "if scipy.sparse.issparse(X_clean):\n",
    "    X_clean_dense = X_clean.A\n",
    "else:\n",
    "    X_clean_dense = X_clean\n",
    "\n",
    "X_clean_df = pd.DataFrame(X_clean_dense, columns=all_cols, index=train_df.index)\n",
    "print(X_clean_df.head())\n",
    "print(f\"All features are now numeric. Shape: {X_clean_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e323e955",
   "metadata": {},
   "source": [
    "## Save Cleaned Dataset\n",
    "Export the cleaned dataset for further analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "859f3726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned numeric dataset saved with shape: (1460, 264)\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned numeric data\n",
    "os.makedirs('../../data/processed/V2', exist_ok=True)\n",
    "X_clean_df.to_csv('../../data/processed/V2/train_advanced_cleaned.csv', index=False)\n",
    "print(f\"Cleaned numeric dataset saved with shape: {X_clean_df.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
